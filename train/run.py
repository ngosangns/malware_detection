import pandas as pd
import numpy as np
import sklearn
import sklearn.ensemble
import sklearn.feature_selection

# read data.csv
data = pd.read_csv('data11.csv', sep='|').drop(['Name', 'md5'], axis=1)

# dataset
X = data.drop(['legitimate'], axis=1).values
y = data['legitimate'].values

# feature selection
fsel = sklearn.ensemble.ExtraTreesClassifier().fit(X, y)
model = sklearn.feature_selection.SelectFromModel(fsel, prefit=True)
X_new = model.transform(X)
nb_features = X_new.shape[1]
indices = np.argsort(fsel.feature_importances_)[::-1][:nb_features]
for f in range(nb_features):
    print("%d. feature %s (%f)" % (f + 1, data.columns[2+indices[f]], fsel.feature_importances_[indices[f]]))
    
# training
algorithms = {
        "DecisionTree": sklearn.tree.DecisionTreeClassifier(max_depth=10),
        "RandomForest": sklearn.ensemble.RandomForestClassifier(n_estimators=50),
        "GradientBoosting": sklearn.ensemble.GradientBoostingClassifier(n_estimators=50),
        "AdaBoost": sklearn.ensemble.AdaBoostClassifier(n_estimators=100),
    }

# testing
results = {}
X_train = data.drop(['legitimate'], axis=1).values
y_train = data['legitimate'].values
X_test = data.tail(2000).drop(['legitimate'], axis=1).values
y_test = data.tail(2000)['legitimate'].values

# result
print("\nNow testing algorithms")
for algo in algorithms:
    clf = algorithms[algo]
    clf.fit(X_train, y_train)
    score = clf.score(X_test, y_test)
    print("%s : %f %%" % (algo, score*100))
    results[algo] = score
winner = max(results, key=results.get)
print('\nWinner algorithm is %s with a %f %% success' % (winner, results[winner]*100))