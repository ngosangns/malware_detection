{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6to4svc.dll\n",
      "7-zip32.dll\n",
      "aaaamon.dll\n",
      "aaclient.dll\n",
      "aadauthhelper.dll\n",
      "aadcloudap.dll\n",
      "aadjcsp.dll\n",
      "aadtb.dll\n",
      "aadWamExtension.dll\n",
      "AboutSettingsHandlers.dll\n",
      "AboveLockAppHost.dll\n",
      "accessibilitycpl.dll\n",
      "ACCMGR.DLL\n",
      "accountaccessor.dll\n",
      "AccountsRt.dll\n",
      "ACCTRES.dll\n",
      "accwiz.exe\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "import pefile\n",
    "import os\n",
    "import hashlib\n",
    "import array\n",
    "import math\n",
    "\n",
    "def get_md5(fname):\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "def get_entropy(data):\n",
    "    if len(data) == 0:\n",
    "        return 0.0\n",
    "    occurences = array.array('L', [0]*256)\n",
    "    for x in data:\n",
    "        occurences[x if isinstance(x, int) else ord(x)] += 1\n",
    "\n",
    "    entropy = 0\n",
    "    for x in occurences:\n",
    "        if x:\n",
    "            p_x = float(x) / len(data)\n",
    "            entropy -= p_x*math.log(p_x, 2)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def get_resources(pe):\n",
    "    \"\"\"Extract resources :\n",
    "    [entropy, size]\"\"\"\n",
    "    resources = []\n",
    "    if hasattr(pe, 'DIRECTORY_ENTRY_RESOURCE'):\n",
    "        try:\n",
    "            for resource_type in pe.DIRECTORY_ENTRY_RESOURCE.entries:\n",
    "                if hasattr(resource_type, 'directory'):\n",
    "                    for resource_id in resource_type.directory.entries:\n",
    "                        if hasattr(resource_id, 'directory'):\n",
    "                            for resource_lang in resource_id.directory.entries:\n",
    "                                data = pe.get_data(resource_lang.data.struct.OffsetToData, resource_lang.data.struct.Size)\n",
    "                                size = resource_lang.data.struct.Size\n",
    "                                entropy = get_entropy(data)\n",
    "\n",
    "                                resources.append([entropy, size])\n",
    "        except Exception as e:\n",
    "            return resources\n",
    "    return resources\n",
    "\n",
    "def get_version_info(pe):\n",
    "    \"\"\"Return version infos\"\"\"\n",
    "    res = {}\n",
    "    for fileinfo in pe.FileInfo:\n",
    "        if fileinfo.Key == 'StringFileInfo':\n",
    "            for st in fileinfo.StringTable:\n",
    "                for entry in st.entries.items():\n",
    "                    res[entry[0]] = entry[1]\n",
    "        if fileinfo.Key == 'VarFileInfo':\n",
    "            for var in fileinfo.Var:\n",
    "                res[var.entry.items()[0][0]] = var.entry.items()[0][1]\n",
    "    if hasattr(pe, 'VS_FIXEDFILEINFO'):\n",
    "          res['flags'] = pe.VS_FIXEDFILEINFO.FileFlags\n",
    "          res['os'] = pe.VS_FIXEDFILEINFO.FileOS\n",
    "          res['type'] = pe.VS_FIXEDFILEINFO.FileType\n",
    "          res['file_version'] = pe.VS_FIXEDFILEINFO.FileVersionLS\n",
    "          res['product_version'] = pe.VS_FIXEDFILEINFO.ProductVersionLS\n",
    "          res['signature'] = pe.VS_FIXEDFILEINFO.Signature\n",
    "          res['struct_version'] = pe.VS_FIXEDFILEINFO.StrucVersion\n",
    "    return res\n",
    "\n",
    "def extract_infos(fpath):\n",
    "    res = []\n",
    "    res.append(os.path.basename(fpath))\n",
    "    res.append(get_md5(fpath))\n",
    "    pe = pefile.PE(fpath)\n",
    "    res.append(pe.FILE_HEADER.Machine)\n",
    "    res.append(pe.FILE_HEADER.SizeOfOptionalHeader)\n",
    "    res.append(pe.FILE_HEADER.Characteristics)\n",
    "    res.append(pe.OPTIONAL_HEADER.MajorLinkerVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.MinorLinkerVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfCode)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfInitializedData)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfUninitializedData)\n",
    "    res.append(pe.OPTIONAL_HEADER.AddressOfEntryPoint)\n",
    "    res.append(pe.OPTIONAL_HEADER.BaseOfCode)\n",
    "    try:\n",
    "        res.append(pe.OPTIONAL_HEADER.BaseOfData)\n",
    "    except AttributeError:\n",
    "        res.append(0)\n",
    "    res.append(pe.OPTIONAL_HEADER.ImageBase)\n",
    "    res.append(pe.OPTIONAL_HEADER.SectionAlignment)\n",
    "    res.append(pe.OPTIONAL_HEADER.FileAlignment)\n",
    "    res.append(pe.OPTIONAL_HEADER.MajorOperatingSystemVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.MinorOperatingSystemVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.MajorImageVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.MinorImageVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.MajorSubsystemVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.MinorSubsystemVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfImage)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfHeaders)\n",
    "    res.append(pe.OPTIONAL_HEADER.CheckSum)\n",
    "    res.append(pe.OPTIONAL_HEADER.Subsystem)\n",
    "    res.append(pe.OPTIONAL_HEADER.DllCharacteristics)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfStackReserve)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfStackCommit)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfHeapReserve)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfHeapCommit)\n",
    "    res.append(pe.OPTIONAL_HEADER.LoaderFlags)\n",
    "    res.append(pe.OPTIONAL_HEADER.NumberOfRvaAndSizes)\n",
    "    res.append(len(pe.sections))\n",
    "    entropy = map(lambda x:x.get_entropy(), pe.sections)\n",
    "    try:\n",
    "        res.append(sum(entropy)/float(len(list(entropy))))\n",
    "    except:\n",
    "        res.append(0)\n",
    "    try:\n",
    "        res.append(min(list(entropy)))\n",
    "    except:\n",
    "        res.append(0)\n",
    "    try:\n",
    "        res.append(max(list(entropy)))\n",
    "    except:\n",
    "        res.append(0)\n",
    "    raw_sizes = map(lambda x:x.SizeOfRawData, pe.sections)\n",
    "    try:\n",
    "        res.append(sum(raw_sizes)/float(len(list(raw_sizes))))\n",
    "    except:\n",
    "        res.append(0)\n",
    "    try:\n",
    "        res.append(min(list(raw_sizes)))\n",
    "    except:\n",
    "        res.append(0)\n",
    "    try:\n",
    "        res.append(max(list(raw_sizes)))\n",
    "    except:\n",
    "        res.append(0)\n",
    "    virtual_sizes = map(lambda x:x.Misc_VirtualSize, pe.sections)\n",
    "    try:\n",
    "        res.append(sum(virtual_sizes)/float(len(list(virtual_sizes))))\n",
    "    except:\n",
    "        res.append(0)\n",
    "    try:\n",
    "        res.append(min(list(virtual_sizes)))\n",
    "    except:\n",
    "        res.append(0)\n",
    "    try:\n",
    "        res.append(max(list(virtual_sizes)))\n",
    "    except:\n",
    "        res.append(0)\n",
    "    #Imports\n",
    "    try:\n",
    "        res.append(len(pe.DIRECTORY_ENTRY_IMPORT))\n",
    "        imports = sum([x.imports for x in pe.DIRECTORY_ENTRY_IMPORT], [])\n",
    "        res.append(len(imports))\n",
    "        res.append(len(list(filter(lambda x:x.name is None, imports))))\n",
    "    except AttributeError:\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "    #Exports\n",
    "    try:\n",
    "        res.append(len(pe.DIRECTORY_ENTRY_EXPORT.symbols))\n",
    "    except AttributeError:\n",
    "        # No export\n",
    "        res.append(0)\n",
    "    #Resources\n",
    "    resources= get_resources(pe)\n",
    "    res.append(len(resources))\n",
    "    if len(resources)> 0:\n",
    "        entropy = map(lambda x:x[0], resources)\n",
    "        try:\n",
    "            res.append(sum(entropy)/float(len(list(entropy))))\n",
    "        except:\n",
    "            res.append(0)\n",
    "        try:\n",
    "            res.append(min(list(entropy)))\n",
    "        except:\n",
    "            res.append(0)\n",
    "        try:\n",
    "            res.append(max(list(entropy)))\n",
    "        except:\n",
    "            res.append(0)\n",
    "        sizes = map(lambda x:x[1], resources)\n",
    "        try:\n",
    "            res.append(sum(sizes)/float(len(list(sizes))))\n",
    "        except:\n",
    "            res.append(0)\n",
    "        try:\n",
    "            res.append(min(list(sizes)))\n",
    "        except:\n",
    "            res.append(0)\n",
    "        try:\n",
    "            res.append(max(list(sizes)))\n",
    "        except:\n",
    "            res.append(0)\n",
    "    else:\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "\n",
    "    # Load configuration size\n",
    "    try:\n",
    "        res.append(pe.DIRECTORY_ENTRY_LOAD_CONFIG.struct.Size)\n",
    "    except AttributeError:\n",
    "        res.append(0)\n",
    "\n",
    "    # Version configuration size\n",
    "    try:\n",
    "        version_infos = get_version_info(pe)\n",
    "        res.append(len(version_infos.keys()))\n",
    "    except AttributeError:\n",
    "        res.append(0)\n",
    "    return res\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    output = \"data.csv\"\n",
    "    csv_delimiter = \"|\"\n",
    "    columns = [\n",
    "        \"Name\",\n",
    "        \"md5\",\n",
    "        \"Machine\",\n",
    "        \"SizeOfOptionalHeader\",\n",
    "        \"Characteristics\",\n",
    "        \"MajorLinkerVersion\",\n",
    "        \"MinorLinkerVersion\",\n",
    "        \"SizeOfCode\",\n",
    "        \"SizeOfInitializedData\",\n",
    "        \"SizeOfUninitializedData\",\n",
    "        \"AddressOfEntryPoint\",\n",
    "        \"BaseOfCode\",\n",
    "        \"BaseOfData\",\n",
    "        \"ImageBase\",\n",
    "        \"SectionAlignment\",\n",
    "        \"FileAlignment\",\n",
    "        \"MajorOperatingSystemVersion\",\n",
    "        \"MinorOperatingSystemVersion\",\n",
    "        \"MajorImageVersion\",\n",
    "        \"MinorImageVersion\",\n",
    "        \"MajorSubsystemVersion\",\n",
    "        \"MinorSubsystemVersion\",\n",
    "        \"SizeOfImage\",\n",
    "        \"SizeOfHeaders\",\n",
    "        \"CheckSum\",\n",
    "        \"Subsystem\",\n",
    "        \"DllCharacteristics\",\n",
    "        \"SizeOfStackReserve\",\n",
    "        \"SizeOfStackCommit\",\n",
    "        \"SizeOfHeapReserve\",\n",
    "        \"SizeOfHeapCommit\",\n",
    "        \"LoaderFlags\",\n",
    "        \"NumberOfRvaAndSizes\",\n",
    "        \"SectionsNb\",\n",
    "        \"SectionsMeanEntropy\",\n",
    "        \"SectionsMinEntropy\",\n",
    "        \"SectionsMaxEntropy\",\n",
    "        \"SectionsMeanRawsize\",\n",
    "        \"SectionsMinRawsize\",\n",
    "        \"SectionMaxRawsize\",\n",
    "        \"SectionsMeanVirtualsize\",\n",
    "        \"SectionsMinVirtualsize\",\n",
    "        \"SectionMaxVirtualsize\",\n",
    "        \"ImportsNbDLL\",\n",
    "        \"ImportsNb\",\n",
    "        \"ImportsNbOrdinal\",\n",
    "        \"ExportNb\",\n",
    "        \"ResourcesNb\",\n",
    "        \"ResourcesMeanEntropy\",\n",
    "        \"ResourcesMinEntropy\",\n",
    "        \"ResourcesMaxEntropy\",\n",
    "        \"ResourcesMeanSize\",\n",
    "        \"ResourcesMinSize\",\n",
    "        \"ResourcesMaxSize\",\n",
    "        \"LoadConfigurationSize\",\n",
    "        \"VersionInformationSize\",\n",
    "        \"legitimate\"\n",
    "    ]\n",
    "\n",
    "    ff = open(output, \"w\")\n",
    "    ff.write(\"sep=|\\n\")\n",
    "    ff.write(csv_delimiter.join(columns) + \"\\n\")\n",
    "\n",
    "    # Launch legitimate\n",
    "    for ffile in os.listdir('data/cv/legitimate'):\n",
    "        print(ffile)\n",
    "        try:\n",
    "            res = extract_infos(os.path.join('data/cv/legitimate/', ffile))\n",
    "            res.append(1)\n",
    "            ff.write(csv_delimiter.join(map(lambda x:str(x), res)) + \"\\n\")\n",
    "        except pefile.PEFormatError:\n",
    "            print('\\t -> Bad PE format')\n",
    "\n",
    "    for ffile in os.listdir('data/cv/malicious'):\n",
    "        print(ffile)\n",
    "        try:\n",
    "            res = extract_infos(os.path.join('data/cv/malicious/', ffile))\n",
    "            res.append(0)\n",
    "\n",
    "            ff.write(csv_delimiter.join(map(lambda x:str(x), res)) + \"\\n\")\n",
    "        except pefile.PEFormatError:\n",
    "            print('\\t -> Bad PE format')\n",
    "        except:\n",
    "            print('\\t -> Weird error')\n",
    "    print(\"Done!\")\n",
    "    ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
